#!/usr/bin/env python3
"""
100% VERIFIED ANALYSIS: Use only matches with BOTH score AND ranking verification
"""
import pandas as pd
import numpy as np
import sys
import os
import pickle
import torch
import torch.nn as nn
from sklearn.metrics import accuracy_score
import xgboost as xgb
import re
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker

class TennisNet(nn.Module):
    def __init__(self, input_size):
        super(TennisNet, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_size, 128), nn.ReLU(), nn.Dropout(0.3),
            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.3),
            nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.2),
            nn.Linear(32, 16), nn.ReLU(), nn.Dropout(0.2),
            nn.Linear(16, 1), nn.Sigmoid()
        )
    
    def forward(self, x):
        return self.network(x)

def get_feature_columns(df):
    exclude_cols = ['tourney_date', 'tourney_name', 'tourney_id', 'match_num', 'winner_id', 'loser_id',
                   'winner_name', 'loser_name', 'score', 'Player1_Name', 'Player2_Name', 'Player1_Wins',
                   'best_of', 'round', 'minutes', 'data_source', 'year']
    return [col for col in df.columns if col not in exclude_cols]

# Define symmetric feature removal list (for 98-feature model)
low_importance_features = [
    # Country pairs (remove both P1 and P2 versions for symmetry)
    'P1_Country_FRA', 'P2_Country_FRA', 'P1_Country_RUS', 'P2_Country_RUS', 
    'P1_Country_ARG', 'P2_Country_ARG', 'P1_Country_GER', 'P2_Country_GER',
    'P1_Country_GBR', 'P2_Country_GBR', 'P1_Country_SRB', 'P2_Country_SRB',
    'P1_Country_AUS', 'P2_Country_AUS', 'P1_Country_ESP', 'P2_Country_ESP',
    'P1_Country_SUI', 'P2_Country_SUI', 'P1_Country_Other', 'P2_Country_Other',
    # Performance pairs (remove both for symmetry)
    'P1_BigMatch_WinRate', 'P2_BigMatch_WinRate', 'P1_Peak_Age', 'P2_Peak_Age',
    'P1_Semifinals_WinRate', 'P2_Semifinals_WinRate', 'P1_Days_Since_Last', 'P2_Days_Since_Last',
    'P1_Hand_A', 'P2_Hand_A', 'P1_Rank_Change_30d', 'P2_Rank_Change_30d', 'P2_Rank_Change_90d',
    # Head-to-head features (inherently asymmetric, remove all)
    'H2H_P1_Wins', 'H2H_P1_WinRate', 'H2H_Recent_P1_Advantage',
    # Tournament/match features (non-paired, remove as-is)
    'Level_C', 'Clay_Season', 'Rank_Ratio', 'Round_Q3',
    # Handedness matchups (symmetric pairs)
    'Handedness_Matchup_LL', 'Handedness_Matchup_RR',
    # Zero importance features (non-paired)
    'Round_Q4', 'Peak_Age_P1', 'Level_G', 'Round_ER', 'Level_S', 'Round_BR', 'Peak_Age_P2'
]

def calculate_betting_accuracy(data, win_col, lose_col):
    odds_data = data.dropna(subset=[win_col, lose_col]).copy()
    if len(odds_data) == 0:
        return None, 0
    
    odds_data[win_col] = pd.to_numeric(odds_data[win_col], errors='coerce')
    odds_data[lose_col] = pd.to_numeric(odds_data[lose_col], errors='coerce')
    odds_clean = odds_data.dropna(subset=[win_col, lose_col])
    
    if len(odds_clean) == 0:
        return None, 0
    
    betting_correct = (odds_clean[win_col] < odds_clean[lose_col]).sum()
    return betting_correct / len(odds_clean), len(odds_clean)

def parse_score_to_sets(score_str):
    """Parse score string to standardized set format"""
    if pd.isna(score_str):
        return None
    
    score_str = str(score_str).strip()
    if any(x in score_str.upper() for x in ['RET', 'W/O', 'DEF', 'WALKOVER']):
        return None
    
    # Extract set scores using regex
    sets = re.findall(r'(\d+)-(\d+)', score_str)
    if len(sets) >= 2:  # At least 2 sets
        return tuple(sets)
    return None

def create_tennis_data_score_sets(row):
    """Create standardized score format from Tennis-Data columns"""
    sets = []
    for i in range(1, 6):  # Up to 5 sets
        w_col = f'W{i}'
        l_col = f'L{i}'
        if pd.notna(row.get(w_col)) and pd.notna(row.get(l_col)):
            try:
                w_score = int(float(row[w_col]))
                l_score = int(float(row[l_col]))
                sets.append((str(w_score), str(l_score)))
            except (ValueError, TypeError):
                continue
    return tuple(sets) if len(sets) >= 2 else None

print("="*80)
print("100% VERIFIED ANALYSIS - IDENTICAL SCORES + RANKINGS ONLY")
print("="*80)

# Load datasets
print("\n1. Loading datasets...")
ml_ready = pd.read_csv('data/JeffSackmann/jeffsackmann_ml_ready_all_years.csv', low_memory=False)
jeff_matched = pd.read_csv('data/JeffSackmann/jeffsackmann_exact_matched_final.csv', low_memory=False)
tennis_matched = pd.read_csv('data/Tennis-Data.co.uk/tennis_data_exact_matched_final.csv', low_memory=False)

ml_ready['tourney_date'] = pd.to_datetime(ml_ready['tourney_date'])
jeff_matched['tourney_date'] = pd.to_datetime(jeff_matched['tourney_date'])
tennis_matched['Date'] = pd.to_datetime(tennis_matched['Date'])

print(f"   Original matched datasets: {len(jeff_matched):,} matches")

# Parse scores and find 100% verified matches
print("\n2. Finding 100% verified matches (identical scores AND rankings)...")
jeff_matched['score_sets'] = jeff_matched['score'].apply(parse_score_to_sets)
tennis_matched['score_sets'] = tennis_matched.apply(create_tennis_data_score_sets, axis=1)

verified_indices = []

for i in range(len(jeff_matched)):
    jeff_row = jeff_matched.iloc[i]
    tennis_row = tennis_matched.iloc[i]
    
    # Check score verification
    score_match = False
    if jeff_row['score_sets'] is not None and tennis_row['score_sets'] is not None:
        score_match = jeff_row['score_sets'] == tennis_row['score_sets']
    
    # Check ranking verification
    ranking_match = False
    try:
        jeff_w_rank = float(jeff_row['winner_rank']) if pd.notna(jeff_row['winner_rank']) else None
        jeff_l_rank = float(jeff_row['loser_rank']) if pd.notna(jeff_row['loser_rank']) else None
        tennis_w_rank = float(tennis_row['WRank']) if pd.notna(tennis_row['WRank']) else None
        tennis_l_rank = float(tennis_row['LRank']) if pd.notna(tennis_row['LRank']) else None
        
        if all(x is not None for x in [jeff_w_rank, jeff_l_rank, tennis_w_rank, tennis_l_rank]):
            ranking_match = (jeff_w_rank == tennis_w_rank) and (jeff_l_rank == tennis_l_rank)
    except (ValueError, TypeError):
        pass
    
    # Only include if BOTH score AND ranking match perfectly
    if score_match and ranking_match:
        verified_indices.append(i)

print(f"   100% verified matches: {len(verified_indices):,}")
print(f"   Verification rate: {len(verified_indices)/len(jeff_matched)*100:.2f}%")
print(f"   Excluded {len(jeff_matched) - len(verified_indices):,} matches with mismatched scores/rankings")

if len(verified_indices) == 0:
    print("   ‚ùå No 100% verified matches found!")
    sys.exit(1)

# Filter to only 100% verified matches
jeff_100_verified = jeff_matched.iloc[verified_indices].copy()
tennis_100_verified = tennis_matched.iloc[verified_indices].copy()

# Create ML-ready dataset for 100% verified matches
print(f"\n3. Creating ML-ready dataset for 100% verified matches...")
ml_verified = []

for _, verified_row in jeff_100_verified.iterrows():
    date = verified_row['tourney_date']
    winner = str(verified_row['winner_name']).strip()
    loser = str(verified_row['loser_name']).strip()
    
    # Find corresponding ML-ready row
    ml_candidates = ml_ready[ml_ready['tourney_date'] == date]
    
    for _, ml_row in ml_candidates.iterrows():
        player1 = str(ml_row['Player1_Name']).strip()
        player2 = str(ml_row['Player2_Name']).strip()
        
        if (player1 == winner and player2 == loser):
            ml_row_copy = ml_row.copy()
            ml_row_copy['Player1_Wins'] = 1
            ml_verified.append(ml_row_copy)
            break
        elif (player1 == loser and player2 == winner):
            ml_row_copy = ml_row.copy()
            ml_row_copy['Player1_Wins'] = 0
            ml_verified.append(ml_row_copy)
            break

ml_verified_df = pd.DataFrame(ml_verified)
print(f"   ML-ready 100% verified: {len(ml_verified_df):,} matches")

if len(ml_verified_df) == 0:
    print("   ‚ùå No ML-ready verified matches found!")
    sys.exit(1)

# Check distribution
ml_verified_df['year'] = ml_verified_df['tourney_date'].dt.year
target_dist = ml_verified_df['Player1_Wins'].mean()
print(f"   Target distribution: {target_dist:.3f}")

year_counts = ml_verified_df['year'].value_counts().sort_index()
for year, count in year_counts.items():
    print(f"   {year}: {count:,} matches")

# Pre-filtering data to remove rows with missing features for consistent alignment
print(f"\nPre-filtering data to remove rows with missing features for consistent alignment...")
original_count = len(ml_verified_df)

# Get all numeric columns first
feature_cols = get_feature_columns(ml_verified_df)
numeric_cols = [col for col in feature_cols if col in ml_verified_df.columns and 
                ml_verified_df[col].dtype in ['int64', 'float64', 'bool']]

# First reset all indices to ensure they match for boolean indexing
ml_verified_df = ml_verified_df.reset_index(drop=True)
tennis_100_verified = tennis_100_verified.reset_index(drop=True)
jeff_100_verified = jeff_100_verified.reset_index(drop=True)

# Remove rows with ANY missing values to ensure perfect alignment
valid_mask = ~ml_verified_df[numeric_cols].isnull().any(axis=1)

# Now apply the valid mask to all datasets
ml_verified_df = ml_verified_df[valid_mask].reset_index(drop=True)
tennis_100_verified = tennis_100_verified[valid_mask].reset_index(drop=True)
jeff_100_verified = jeff_100_verified[valid_mask].reset_index(drop=True)

filtered_count = len(ml_verified_df)
print(f"Filtered from {original_count:,} to {filtered_count:,} matches (removed rows with missing features)")

# Prepare features
print(f"\n4. Preparing features...")
X_test = ml_verified_df[numeric_cols]  # No fillna needed after filtering
y_test = ml_verified_df['Player1_Wins']

print(f"   Features: {len(numeric_cols)}, Shape: {X_test.shape}")

# Calculate baselines on 100% verified data
print(f"\n5. Calculating baselines (100% verified data)...")

# ATP ranking baseline
atp_clean = jeff_100_verified.dropna(subset=['winner_rank', 'loser_rank']).copy()
atp_clean['winner_rank'] = pd.to_numeric(atp_clean['winner_rank'], errors='coerce')
atp_clean['loser_rank'] = pd.to_numeric(atp_clean['loser_rank'], errors='coerce')
atp_clean = atp_clean.dropna(subset=['winner_rank', 'loser_rank'])

atp_correct = (atp_clean['winner_rank'] < atp_clean['loser_rank']).sum()
atp_accuracy = atp_correct / len(atp_clean)
print(f"   ATP Baseline: {atp_accuracy:.4f} ({atp_accuracy*100:.2f}%) on {len(atp_clean):,} matches")

# Betting odds
betting_acc, betting_count = calculate_betting_accuracy(tennis_100_verified, 'AvgW', 'AvgL')
print(f"   Betting Odds: {betting_acc:.4f} ({betting_acc*100:.2f}%) on {betting_count:,} matches")

# Test models
print(f"\n6. Testing models (100% verified data)...")
results = {}

# All models now use the same 143-feature set (exact_143_features list from training scripts)
exact_143_features = [
    'P2_WinStreak_Current', 'P1_WinStreak_Current', 'P2_Surface_Matches_30d', 'Height_Diff',
    'P1_Surface_Matches_30d', 'Player2_Height', 'P1_Matches_30d', 'P2_Matches_30d',
    'P2_Surface_Experience', 'P2_Form_Trend_30d', 'Player1_Height', 'P1_Form_Trend_30d',
    'Round_R16', 'Surface_Transition_Flag', 'P1_Surface_Matches_90d', 'P1_Surface_Experience',
    'Rank_Diff', 'Round_R32', 'Rank_Points_Diff', 'P2_Level_WinRate_Career',
    'P2_Surface_Matches_90d', 'P1_Level_WinRate_Career', 'P2_Level_Matches_Career',
    'P2_WinRate_Last10_120d', 'Round_QF', 'Level_25', 'P1_Round_WinRate_Career',
    'P1_Surface_WinRate_90d', 'Round_Q1', 'Player1_Rank', 'P1_Level_Matches_Career',
    'P2_Round_WinRate_Career', 'draw_size', 'P1_WinRate_Last10_120d', 'Age_Diff',
    'Level_15', 'Player1_Rank_Points', 'Handedness_Matchup_RL', 'Player2_Rank',
    'Avg_Age', 'P1_Country_RUS', 'Player2_Age', 'P2_vs_Lefty_WinRate',
    'Round_F', 'Surface_Clay', 'P2_Sets_14d', 'Rank_Momentum_Diff_30d',
    'H2H_P2_Wins', 'Player2_Rank_Points', 'Player1_Age', 'P2_Rank_Volatility_90d',
    'P1_Days_Since_Last', 'Grass_Season', 'P1_Semifinals_WinRate', 'Level_A',
    'Level_D', 'P1_Country_USA', 'P1_Country_GBR', 'P1_Country_FRA',
    'P2_Matches_14d', 'P2_Country_USA', 'P2_Country_ITA', 'Round_Q2',
    'P2_Surface_WinRate_90d', 'P1_Hand_L', 'P2_Hand_L', 'P1_Country_ITA',
    'P2_Rust_Flag', 'P1_Rank_Change_90d', 'P1_Country_AUS', 'P1_Hand_U',
    'P1_Hand_R', 'Round_RR', 'Avg_Height', 'P1_Sets_14d',
    'P2_Country_Other', 'Round_SF', 'P1_vs_Lefty_WinRate', 'Indoor_Season',
    'Avg_Rank', 'P1_Rust_Flag', 'Avg_Rank_Points', 'Level_F',
    'Round_R64', 'P2_Country_CZE', 'P2_Hand_R', 'Surface_Hard',
    'P1_Matches_14d', 'Surface_Carpet', 'Round_R128', 'P1_Country_SRB',
    'P2_Hand_U', 'P1_Rank_Volatility_90d', 'Level_M', 'P2_Country_ESP',
    'Handedness_Matchup_LR', 'P1_Country_CZE', 'P2_Country_SUI', 'Surface_Grass',
    'H2H_Total_Matches', 'Level_O', 'P1_Hand_A', 'P1_Finals_WinRate',
    'Rank_Momentum_Diff_90d', 'P2_Finals_WinRate',
    # Zero importance features (7 total)
    'Round_Q4', 'Peak_Age_P1', 'Level_G', 'Round_ER', 'Level_S', 'Round_BR', 'Peak_Age_P2',
    # Negative importance features (31 total) 
    'Round_Q3', 'Rank_Ratio', 'P1_Country_SUI', 'Clay_Season', 'P1_Country_GER',
    'P2_Rank_Change_30d', 'P1_Country_ESP', 'P2_Hand_A', 'H2H_Recent_P1_Advantage',
    'P2_Country_AUS', 'P2_Country_SRB', 'P2_Country_GBR', 'P2_Country_ARG',
    'Handedness_Matchup_RR', 'P1_Rank_Change_30d', 'P2_Country_GER', 'Handedness_Matchup_LL',
    'P2_Country_RUS', 'P1_Country_ARG', 'Level_C', 'P2_Semifinals_WinRate',
    'P2_Days_Since_Last', 'P1_Peak_Age', 'P2_Peak_Age', 'H2H_P1_WinRate',
    'P1_Country_Other', 'H2H_P1_Wins', 'P1_BigMatch_WinRate', 'P2_Rank_Change_90d',
    'P2_BigMatch_WinRate', 'P2_Country_FRA'
]

# Use exact same 143 features for XGBoost, Random Forest, and Neural Network 143
feature_cols_143 = [col for col in exact_143_features if col in ml_verified_df.columns]
X_test_143 = ml_verified_df[feature_cols_143]  # No fillna needed after pre-filtering

# XGBoost
xgb_path = 'results/professional_tennis/XGBoost/xgboost_model.json'
if os.path.exists(xgb_path):
    try:
        xgb_model = xgb.XGBClassifier()
        xgb_model.load_model(xgb_path)
        xgb_pred = xgb_model.predict(X_test_143)
        xgb_acc = accuracy_score(y_test, xgb_pred)
        results['XGBoost'] = xgb_acc
        print(f"   XGBoost: {xgb_acc:.4f} ({xgb_acc*100:.2f}%) using {len(feature_cols_143)} features")
    except Exception as e:
        print(f"   XGBoost failed: {e}")

# Random Forest
rf_path = 'results/professional_tennis/Random_Forest/random_forest_model.pkl'
if os.path.exists(rf_path):
    try:
        with open(rf_path, 'rb') as f:
            rf_model = pickle.load(f)
        rf_pred = rf_model.predict(X_test_143)
        rf_acc = accuracy_score(y_test, rf_pred)
        results['Random_Forest'] = rf_acc
        print(f"   Random Forest: {rf_acc:.4f} ({rf_acc*100:.2f}%) using {len(feature_cols_143)} features")
    except Exception as e:
        print(f"   Random Forest failed: {e}")

# Neural Network (143-feature)
nn_path_143 = 'results/professional_tennis/Neural_Network/neural_network_143_features.pth'
scaler_path_143 = 'results/professional_tennis/Neural_Network/scaler_143_features.pkl'
if os.path.exists(nn_path_143) and os.path.exists(scaler_path_143):
    try:
        with open(scaler_path_143, 'rb') as f:
            scaler_143 = pickle.load(f)
        
        nn_model_143 = TennisNet(len(feature_cols_143))
        nn_model_143.load_state_dict(torch.load(nn_path_143, map_location='cpu'))
        nn_model_143.eval()
        
        # Use exact same 143 features as the model was trained on
        X_scaled_143 = scaler_143.transform(X_test_143.values)
        X_tensor_143 = torch.FloatTensor(X_scaled_143)
        
        with torch.no_grad():
            nn_pred_proba_143 = nn_model_143(X_tensor_143).squeeze().numpy()
            nn_pred_143 = (nn_pred_proba_143 > 0.5).astype(int)
        
        nn_acc_143 = accuracy_score(y_test, nn_pred_143)
        results['Neural_Network_143'] = nn_acc_143
        print(f"   Neural Network (143-feature): {nn_acc_143:.4f} ({nn_acc_143*100:.2f}%) using {len(feature_cols_143)} features")
    except Exception as e:
        print(f"   Neural Network (143-feature) failed: {e}")

# Neural Network (98-feature)
nn_path_98 = 'results/professional_tennis/Neural_Network/neural_network_symmetric_features.pth'
scaler_path_98 = 'results/professional_tennis/Neural_Network/scaler_symmetric_features.pkl'
if os.path.exists(nn_path_98) and os.path.exists(scaler_path_98):
    try:
        with open(scaler_path_98, 'rb') as f:
            scaler_98 = pickle.load(f)
        
        # Filter features for 98-feature model using the same approach as training
        # Use ALL numeric features, then remove low importance ones (like training did)
        all_numeric_cols = [col for col in numeric_cols if col not in low_importance_features]
        X_test_98_cols = all_numeric_cols
        
        print(f"   DEBUG: 98-feature model scaler expects {scaler_98.n_features_in_} features, got {len(X_test_98_cols)} features")
        
        # Debug: Show which features from low_importance_features aren't actually in feature_cols_143
        expected_features = scaler_98.n_features_in_
        if len(X_test_98_cols) != expected_features:
            missing_from_removal = [f for f in low_importance_features if f not in feature_cols_143]
            print(f"   DEBUG: Features in low_importance_features but not in current data: {missing_from_removal}")
            print(f"   DEBUG: Expected to remove {len(low_importance_features)} features, but only {len([f for f in low_importance_features if f in feature_cols_143])} are present")
            
            # Calculate how many more features we need to remove to get to 98
            features_to_remove_more = len(X_test_98_cols) - expected_features
            if features_to_remove_more > 0:
                print(f"   DEBUG: Need to remove {features_to_remove_more} more features to match trained model")
                # For now, just take the first 98 features to match the scaler
                X_test_98_cols = X_test_98_cols[:expected_features]
                print(f"   WARNING: Truncated to first {expected_features} features to match trained model")
        
        X_test_98 = ml_verified_df[X_test_98_cols]  # No fillna needed after pre-filtering
        
        nn_model_98 = TennisNet(len(X_test_98_cols))
        nn_model_98.load_state_dict(torch.load(nn_path_98, map_location='cpu'))
        nn_model_98.eval()
        
        X_scaled_98 = scaler_98.transform(X_test_98.values)
        X_tensor_98 = torch.FloatTensor(X_scaled_98)
        
        with torch.no_grad():
            nn_pred_proba_98 = nn_model_98(X_tensor_98).squeeze().numpy()
            nn_pred_98 = (nn_pred_proba_98 > 0.5).astype(int)
        
        nn_acc_98 = accuracy_score(y_test, nn_pred_98)
        results['Neural_Network_98'] = nn_acc_98
        print(f"   Neural Network (98-feature): {nn_acc_98:.4f} ({nn_acc_98*100:.2f}%) using {len(X_test_98_cols)} features")
    except Exception as e:
        print(f"   Neural Network (98-feature) failed: {e}")

# Year-by-year breakdown
print(f"\n7. Year-by-year breakdown (100% verified)...")
for year in [2023, 2024]:
    year_data = ml_verified_df[ml_verified_df['year'] == year]
    year_tennis = tennis_100_verified[tennis_100_verified['Date'].dt.year == year]
    
    if len(year_data) == 0:
        continue
        
    print(f"\n   {year} ({len(year_data):,} matches):") 
    
    # ATP baseline
    year_jeff = jeff_100_verified[jeff_100_verified['tourney_date'].dt.year == year]
    year_atp = year_jeff.dropna(subset=['winner_rank', 'loser_rank']).copy()
    year_atp['winner_rank'] = pd.to_numeric(year_atp['winner_rank'], errors='coerce')
    year_atp['loser_rank'] = pd.to_numeric(year_atp['loser_rank'], errors='coerce')
    year_atp = year_atp.dropna(subset=['winner_rank', 'loser_rank'])
    
    if len(year_atp) > 0:
        year_atp_correct = (year_atp['winner_rank'] < year_atp['loser_rank']).sum()
        year_atp_acc = year_atp_correct / len(year_atp)
        print(f"     ATP Baseline: {year_atp_acc:.4f} ({year_atp_acc*100:.2f}%)")
    
    # Betting odds
    year_betting_acc, _ = calculate_betting_accuracy(year_tennis, 'AvgW', 'AvgL')
    if year_betting_acc is not None:
        print(f"     Betting Odds: {year_betting_acc:.4f} ({year_betting_acc*100:.2f}%)")
    
    # Models
    year_X = year_data[numeric_cols].fillna(year_data[numeric_cols].median())
    year_y = year_data['Player1_Wins']
    
    for model_name in results:
        if model_name == 'XGBoost':
            year_X_143 = year_data[feature_cols_143]  # No fillna needed after pre-filtering
            year_pred = xgb_model.predict(year_X_143)
        elif model_name == 'Random_Forest':
            year_X_143 = year_data[feature_cols_143]  # No fillna needed after pre-filtering
            year_pred = rf_model.predict(year_X_143)
        elif model_name == 'Neural_Network_143':
            year_X_143 = year_data[feature_cols_143]  # No fillna needed after pre-filtering
            year_X_scaled = scaler_143.transform(year_X_143.values)
            year_X_tensor = torch.FloatTensor(year_X_scaled)
            with torch.no_grad():
                year_pred_proba = nn_model_143(year_X_tensor).squeeze().numpy()
                year_pred = (year_pred_proba > 0.5).astype(int)
        elif model_name == 'Neural_Network_98':
            # Use same X_test_98_cols definition for consistency
            year_X_98 = year_data[X_test_98_cols]  # No fillna needed after pre-filtering
            year_X_scaled = scaler_98.transform(year_X_98.values)
            year_X_tensor = torch.FloatTensor(year_X_scaled)
            with torch.no_grad():
                year_pred_proba = nn_model_98(year_X_tensor).squeeze().numpy()
                year_pred = (year_pred_proba > 0.5).astype(int)
        
        year_acc = accuracy_score(year_y, year_pred)
        display_name = model_name.replace('_', ' ').replace('Neural Network', 'NN')
        print(f"     {display_name}: {year_acc:.4f} ({year_acc*100:.2f}%)")

# Final comparison
print(f"\n" + "="*80)
print(f"100% VERIFIED COMPARISON - {len(ml_verified_df):,} IDENTICAL MATCHES")
print(f"(Only matches with BOTH identical scores AND rankings)")
print(f"="*80)

all_results = {'ATP_Baseline': atp_accuracy, 'Betting_Odds': betting_acc, **results}
sorted_results = sorted(all_results.items(), key=lambda x: x[1], reverse=True)

print(f"Performance Rankings (100% Verified):")
for i, (method, acc) in enumerate(sorted_results):
    if method == 'Betting_Odds':
        name = "Professional Betting Odds"
    elif method == 'ATP_Baseline':
        name = "ATP Ranking Baseline"
    else:
        name = f"Your {method.replace('_', ' ')} Model"
    
    print(f"   {i+1}. {name}: {acc:.4f} ({acc*100:.2f}%)")

# Winners vs betting odds
winners = [m for m, acc in results.items() if acc > betting_acc]
if winners:
    print(f"\nüéâ MODELS BEATING BETTING ODDS (100% verified):") 
    for model in winners:
        improvement = (results[model] - betting_acc) * 100
        print(f"   {model}: +{improvement:.2f} percentage points")
else:
    print(f"\nüìä No models beat betting odds on 100% verified data")
    if results:
        best = max(results.items(), key=lambda x: x[1])
        gap = (betting_acc - best[1]) * 100
        print(f"   Best model ({best[0]}): -{gap:.2f} percentage points")

print(f"\n‚úÖ 100% verified apples-to-apples comparison complete!")

# ============================================================================
# KELLY CRITERION BETTING SIMULATION
# ============================================================================

def decimal_to_implied_prob(decimal_odds):
    """Convert decimal odds to implied probability"""
    return 1.0 / decimal_odds

def kelly_fraction(model_prob, decimal_odds):
    """Calculate Kelly Criterion betting fraction"""
    b = decimal_odds - 1  # Net odds
    p = model_prob       # Model probability
    q = 1 - p           # 1 - model probability
    kelly = (b * p - q) / b
    return max(0, kelly)  # Never bet negative amounts

def run_kelly_simulation(model_name, predictions, probabilities, verified_tennis_data, verified_ml_data):
    """Run Kelly betting simulation for a single model"""
    STARTING_BANKROLL = 100.0
    MAX_BET_PCT = 0.05  # Never bet more than 5% of bankroll (Kelly cap)
    MIN_EDGE = 0.02     # Require at least 2% edge
    MIN_BET = 0.01      # Minimum bet size
    
    bankroll = STARTING_BANKROLL
    total_bets = 0
    winning_bets = 0
    total_profit = 0
    bet_history = []
    
    for i in range(len(verified_ml_data)):
        tennis_row = verified_tennis_data.iloc[i]
        ml_row = verified_ml_data.iloc[i]
        
        # Get betting odds - AvgW/AvgL are winner/loser odds, need to assign correctly
        avg_winner_odds = tennis_row.get('AvgW', None)
        avg_loser_odds = tennis_row.get('AvgL', None)
        
        if pd.isna(avg_winner_odds) or pd.isna(avg_loser_odds) or avg_winner_odds <= 1 or avg_loser_odds <= 1:
            continue
            
        avg_winner_odds = float(avg_winner_odds)
        avg_loser_odds = float(avg_loser_odds)
        
        # Assign odds based on actual match outcome (who actually won/lost)
        actual_p1_win = ml_row['Player1_Wins']
        if actual_p1_win == 1:
            p1_odds = avg_winner_odds  # Player1 won, gets winner odds
            p2_odds = avg_loser_odds   # Player2 lost, gets loser odds
        else:
            p1_odds = avg_loser_odds   # Player1 lost, gets loser odds
            p2_odds = avg_winner_odds  # Player2 won, gets winner odds
            
        # Get model probabilities
        if probabilities is not None:
            model_p1_prob = probabilities[i] if i < len(probabilities) else 0.5
        else:
            model_p1_prob = 0.5  # Fallback
            
        # Market probabilities
        market_p1_prob = decimal_to_implied_prob(p1_odds)
        market_p2_prob = decimal_to_implied_prob(p2_odds)
        
        # Calculate edges
        edge_p1 = model_p1_prob - market_p1_prob
        edge_p2 = (1 - model_p1_prob) - market_p2_prob
        
        # Determine best bet
        bet_on_p1 = None
        odds_used = None
        model_prob_used = None
        market_prob_used = None
        edge_used = None
        
        if edge_p1 > MIN_EDGE and edge_p1 > edge_p2:
            bet_on_p1 = True
            odds_used = p1_odds
            model_prob_used = model_p1_prob
            market_prob_used = market_p1_prob
            edge_used = edge_p1
        elif edge_p2 > MIN_EDGE:
            bet_on_p1 = False
            odds_used = p2_odds
            model_prob_used = 1 - model_p1_prob
            market_prob_used = market_p2_prob
            edge_used = edge_p2
        else:
            continue  # No good bet
            
        # Calculate Kelly bet size
        kelly_frac = kelly_fraction(model_prob_used, odds_used)
        kelly_frac = min(kelly_frac, MAX_BET_PCT)  # Cap at max bet
        
        bet_amount = bankroll * kelly_frac
        if bet_amount < MIN_BET or bankroll < MIN_BET:
            continue
            
        # Place bet
        actual_p1_win = ml_row['Player1_Wins']
        bet_won = (bet_on_p1 and actual_p1_win == 1) or (not bet_on_p1 and actual_p1_win == 0)
        
        if bet_won:
            profit = bet_amount * (odds_used - 1)
            winning_bets += 1
        else:
            profit = -bet_amount
            
        bankroll += profit
        total_profit += profit
        total_bets += 1
        
        # Debug Cobolli match
        if 'Sasi Kumar Mukund' in [ml_row['Player1_Name'], ml_row['Player2_Name']]:
            print(f"DEBUG {model_name} match {i}: {ml_row['Player1_Name']} vs {ml_row['Player2_Name']}")
            print(f"  actual_p1_win: {actual_p1_win}, p1_odds: {p1_odds}, p2_odds: {p2_odds}")
            print(f"  model_p1_prob: {model_p1_prob}, edge_p1: {edge_p1}, edge_p2: {edge_p2}")
            if bet_on_p1 is not None:
                bet_on_player = ml_row['Player1_Name'] if bet_on_p1 else ml_row['Player2_Name']
                print(f"  bet_on_p1: {bet_on_p1}, bet_on_player: {bet_on_player}, odds_used: {odds_used}, market_prob_bet_on: {market_prob_used}")
        
        # Log bet
        bet_history.append({
            'bet_number': total_bets,
            'match_index': i,
            'date': ml_row.get('tourney_date', ''),
            'player1': ml_row.get('Player1_Name', ''),
            'player2': ml_row.get('Player2_Name', ''),
            'bet_on_player': ml_row['Player1_Name'] if bet_on_p1 else ml_row['Player2_Name'],
            'bet_on_p1': bet_on_p1,
            'actual_p1_win': actual_p1_win,
            'model_p1_prob': model_p1_prob,
            'model_prob_bet_on': model_prob_used,
            'market_prob_bet_on': market_prob_used,
            'edge': edge_used,
            'kelly_fraction': kelly_frac,
            'bankroll_before': bankroll - profit,
            'bet_amount': bet_amount,
            'bet_as_pct_bankroll': kelly_frac,
            'odds_used': odds_used,
            'bet_won': bet_won,
            'profit': profit,
            'bankroll_after': bankroll,
            'bankroll_growth': bankroll / STARTING_BANKROLL,
            'total_return_pct': ((bankroll - STARTING_BANKROLL) / STARTING_BANKROLL) * 100
        })
    
    # Calculate final stats
    win_rate = winning_bets / total_bets if total_bets > 0 else 0
    total_return_pct = ((bankroll - STARTING_BANKROLL) / STARTING_BANKROLL) * 100
    roi = (total_profit / (total_bets * STARTING_BANKROLL * MAX_BET_PCT)) * 100 if total_bets > 0 else 0
    
    return {
        'model_name': model_name,
        'final_bankroll': bankroll,
        'total_return_pct': total_return_pct,
        'total_bets': total_bets,
        'winning_bets': winning_bets,
        'win_rate': win_rate,
        'total_profit': total_profit,
        'bet_history': bet_history,
        'roi': roi
    }

print(f"\n" + "="*80)
print(f"KELLY CRITERION BETTING SIMULATION")
print(f"="*80)

# Prepare model predictions and probabilities for betting simulation
model_predictions = {}
model_probabilities = {}

# Get probabilities for each model
if 'XGBoost' in results:
    xgb_proba = xgb_model.predict_proba(X_test_143)[:, 1]
    model_predictions['XGBoost'] = (xgb_proba > 0.5).astype(int)
    model_probabilities['XGBoost'] = xgb_proba

if 'Random_Forest' in results:
    rf_proba = rf_model.predict_proba(X_test_143)[:, 1]
    model_predictions['Random_Forest'] = (rf_proba > 0.5).astype(int)
    model_probabilities['Random_Forest'] = rf_proba

if 'Neural_Network_143' in results:
    # Get probabilities for 143-feature model using exact same features as training
    X_scaled_143_nn = scaler_143.transform(X_test_143.values)
    X_tensor_143_nn = torch.FloatTensor(X_scaled_143_nn)
    
    with torch.no_grad():
        nn_proba_143 = nn_model_143(X_tensor_143_nn).squeeze().numpy()
    
    model_predictions['Neural_Network_143'] = (nn_proba_143 > 0.5).astype(int)
    model_probabilities['Neural_Network_143'] = nn_proba_143

if 'Neural_Network_98' in results:
    # Get probabilities for 98-feature model using exact same features as training
    # Use the same X_test_98 that was created during model testing
    X_scaled_98_nn = scaler_98.transform(X_test_98.values)
    X_tensor_98_nn = torch.FloatTensor(X_scaled_98_nn)
    
    with torch.no_grad():
        nn_proba_98 = nn_model_98(X_tensor_98_nn).squeeze().numpy()
    
    model_predictions['Neural_Network_98'] = (nn_proba_98 > 0.5).astype(int)
    model_probabilities['Neural_Network_98'] = nn_proba_98

# Debug: Check array lengths before Kelly simulation
print(f"\nDEBUG: Checking model prediction array lengths:")
print(f"Total verified matches: {len(ml_verified_df):,}")
for model_name in model_predictions.keys():
    pred_len = len(model_predictions[model_name])
    prob_len = len(model_probabilities[model_name])
    print(f"{model_name}: predictions={pred_len:,}, probabilities={prob_len:,}")
    if pred_len != len(ml_verified_df):
        print(f"  ‚ö†Ô∏è  WARNING: {model_name} has {pred_len} predictions but should have {len(ml_verified_df)}")

# Run Kelly simulation for each model
kelly_results = {}
for model_name in model_predictions.keys():
    print(f"\nRunning Kelly simulation for {model_name.replace('_', ' ')}...")
    
    result = run_kelly_simulation(
        model_name, 
        model_predictions[model_name],
        model_probabilities[model_name], 
        tennis_100_verified, 
        ml_verified_df
    )
    
    kelly_results[model_name] = result
    
    print(f"   Final bankroll: ${result['final_bankroll']:.2f}")
    print(f"   Total return: {result['total_return_pct']:+.1f}%")
    print(f"   Bets placed: {result['total_bets']:,}")
    print(f"   Win rate: {result['win_rate']:.1%}")
    print(f"   Bet frequency: {result['total_bets']/len(ml_verified_df)*100:.1f}% of matches")

# Save detailed betting logs
print(f"\n8. Saving detailed betting logs...")
os.makedirs('analysis_scripts/betting_logs', exist_ok=True)

for model_name, result in kelly_results.items():
    if len(result['bet_history']) > 0:
        bet_df = pd.DataFrame(result['bet_history'])
        filename = f"analysis_scripts/betting_logs/kelly_{model_name.lower()}_bets.csv"
        bet_df.to_csv(filename, index=False)
        print(f"   {model_name} betting log saved: {filename}")

# Generate bankroll over time charts
print(f"\n9. Generating bankroll over time charts...")
os.makedirs('analysis_scripts/charts', exist_ok=True)

# Create a 2x2 subplot layout for all 4 models
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('Kelly Betting Strategy: Bankroll Over Time', fontsize=16, fontweight='bold')

model_positions = {
    'XGBoost': (0, 0),
    'Random_Forest': (0, 1), 
    'Neural_Network_143': (1, 0),
    'Neural_Network_98': (1, 1)
}

colors = {
    'XGBoost': '#2E86AB',
    'Random_Forest': '#A23B72', 
    'Neural_Network_143': '#F18F01',
    'Neural_Network_98': '#C73E1D'
}

for model_name, result in kelly_results.items():
    if len(result['bet_history']) > 0 and model_name in model_positions:
        row, col = model_positions[model_name]
        ax = axes[row, col]
        
        bet_df = pd.DataFrame(result['bet_history'])
        
        # Plot bankroll over bet number
        ax.plot(bet_df['bet_number'], bet_df['bankroll_after'], 
                color=colors[model_name], linewidth=2, alpha=0.8)
        
        # Clean model name for display
        display_name = model_name.replace('_', ' ').replace('Neural Network', 'Neural Net')
        
        # Format final return percentage
        final_return = result['total_return_pct']
        if final_return >= 0:
            return_text = f"+{final_return:.1f}%"
            return_color = 'green'
        else:
            return_text = f"{final_return:.1f}%"
            return_color = 'red'
        
        ax.set_title(f'{display_name}\n{return_text} Return ({result["total_bets"]} bets)', 
                    fontsize=12, fontweight='bold', color=return_color)
        ax.set_xlabel('Bet Number', fontsize=10)
        ax.set_ylabel('Bankroll ($)', fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # Format y-axis to avoid scientific notation
        ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'${x:,.0f}'))
        
        # Set reasonable y-axis limits to avoid extreme scaling
        max_bankroll = bet_df['bankroll_after'].max()
        min_bankroll = bet_df['bankroll_after'].min()
        
        if max_bankroll > 1000:
            ax.set_ylim(bottom=max(0, min_bankroll * 0.9))
        else:
            ax.set_ylim(0, max_bankroll * 1.1)
        
        # Add horizontal line at starting bankroll ($100)
        ax.axhline(y=100, color='black', linestyle='--', alpha=0.5, linewidth=1)
        ax.text(0.02, 0.95, 'Start: $100', transform=ax.transAxes, 
                fontsize=9, verticalalignment='top', alpha=0.7)

plt.tight_layout()
plt.savefig('analysis_scripts/charts/kelly_bankroll_overtime_all_models.png', 
            dpi=300, bbox_inches='tight', facecolor='white')
print(f"   Combined chart saved: analysis_scripts/charts/kelly_bankroll_overtime_all_models.png")

# Also create individual charts for each model
for model_name, result in kelly_results.items():
    if len(result['bet_history']) > 0:
        plt.figure(figsize=(12, 8))
        
        bet_df = pd.DataFrame(result['bet_history'])
        
        plt.plot(bet_df['bet_number'], bet_df['bankroll_after'], 
                color=colors.get(model_name, '#333333'), linewidth=2.5)
        
        display_name = model_name.replace('_', ' ').replace('Neural Network', 'Neural Net')
        final_return = result['total_return_pct']
        
        if final_return >= 0:
            return_text = f"+{final_return:.1f}%"
            title_color = 'darkgreen'
        else:
            return_text = f"{final_return:.1f}%"
            title_color = 'darkred'
            
        plt.title(f'{display_name} - Kelly Betting Strategy\n{return_text} Return ({result["total_bets"]} bets, {result["win_rate"]:.1%} win rate)', 
                 fontsize=14, fontweight='bold', color=title_color, pad=20)
        plt.xlabel('Bet Number', fontsize=12)
        plt.ylabel('Bankroll ($)', fontsize=12)
        plt.grid(True, alpha=0.3)
        
        # Format y-axis nicely
        plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'${x:,.0f}'))
        
        # Add horizontal line at starting bankroll
        plt.axhline(y=100, color='black', linestyle='--', alpha=0.5, linewidth=1, label='Starting Bankroll')
        
        # Set y-axis limits
        max_bankroll = bet_df['bankroll_after'].max()
        min_bankroll = bet_df['bankroll_after'].min()
        
        if max_bankroll > 1000:
            plt.ylim(bottom=max(0, min_bankroll * 0.9))
        else:
            plt.ylim(0, max_bankroll * 1.1)
        
        plt.tight_layout()
        filename = f"analysis_scripts/charts/kelly_{model_name.lower()}_bankroll_overtime.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        print(f"   {display_name} chart saved: {filename}")

plt.close('all')  # Close all remaining figures

# Additional Analysis: Fixed Bankroll Kelly Strategy
print(f"\n" + "="*80)
print(f"FIXED BANKROLL KELLY ANALYSIS")
print(f"(Kelly sizing based on original $100, no compounding)")
print(f"="*80)

def run_fixed_bankroll_kelly(model_name, predictions, probabilities, verified_tennis_data, verified_ml_data):
    """Run Kelly betting with fixed $100 bankroll for bet sizing - NO CAP (full Kelly)"""
    FIXED_BANKROLL = 100.0  # Always calculate bet size based on $100
    ACTUAL_BANKROLL = 100.0  # Track actual money
    # MAX_BET_PCT removed - using full Kelly sizing now
    MIN_EDGE = 0.02
    MIN_BET = 0.01
    
    total_bets = 0
    winning_bets = 0
    total_profit = 0
    bet_history = []

    for i in range(len(verified_ml_data)):
        tennis_row = verified_tennis_data.iloc[i]
        ml_row = verified_ml_data.iloc[i]
        
        # Get betting odds (same logic as before)
        avg_winner_odds = tennis_row.get('AvgW', None)
        avg_loser_odds = tennis_row.get('AvgL', None)
        
        if pd.isna(avg_winner_odds) or pd.isna(avg_loser_odds) or avg_winner_odds <= 1 or avg_loser_odds <= 1:
            continue
            
        avg_winner_odds = float(avg_winner_odds)
        avg_loser_odds = float(avg_loser_odds)
        
        actual_p1_win = ml_row['Player1_Wins']
        if actual_p1_win == 1:
            p1_odds = avg_winner_odds
            p2_odds = avg_loser_odds
        else:
            p1_odds = avg_loser_odds
            p2_odds = avg_winner_odds
        
        model_p1_prob = probabilities[i] if i < len(probabilities) else 0.5
        
        market_p1_prob = 1.0 / p1_odds
        market_p2_prob = 1.0 / p2_odds
        
        edge_p1 = model_p1_prob - market_p1_prob
        edge_p2 = (1 - model_p1_prob) - market_p2_prob
        
        # Determine best bet (same logic)
        bet_on_p1 = None
        odds_used = None
        model_prob_used = None
        market_prob_used = None
        edge_used = None
        
        if edge_p1 > MIN_EDGE and edge_p1 > edge_p2:
            bet_on_p1 = True
            odds_used = p1_odds
            model_prob_used = model_p1_prob
            market_prob_used = market_p1_prob
            edge_used = edge_p1
        elif edge_p2 > MIN_EDGE:
            bet_on_p1 = False
            odds_used = p2_odds
            model_prob_used = 1 - model_p1_prob
            market_prob_used = market_p2_prob
            edge_used = edge_p2
        else:
            continue
        
        # Calculate Kelly bet size based on FIXED $100 bankroll - FULL KELLY (no cap)
        b = odds_used - 1
        p = model_prob_used
        q = 1 - p
        kelly_frac = (b * p - q) / b
        kelly_frac = max(0, kelly_frac)  # Remove MAX_BET_PCT cap - using full Kelly
        
        # Bet amount based on fixed $100 - ALWAYS bet the Kelly amount regardless of current bankroll
        bet_amount = FIXED_BANKROLL * kelly_frac
        
        if bet_amount < MIN_BET:
            continue
            
        # Calculate outcome
        bet_won = (bet_on_p1 and actual_p1_win == 1) or (not bet_on_p1 and actual_p1_win == 0)
        
        if bet_won:
            profit = bet_amount * (odds_used - 1)
            winning_bets += 1
        else:
            profit = -bet_amount
            
        ACTUAL_BANKROLL += profit
        total_profit += profit
        total_bets += 1
        
        # Log bet
        bet_history.append({
            'bet_number': total_bets,
            'match_index': i,
            'date': ml_row.get('tourney_date', ''),
            'player1': ml_row.get('Player1_Name', ''),
            'player2': ml_row.get('Player2_Name', ''),
            'bet_on_player': ml_row['Player1_Name'] if bet_on_p1 else ml_row['Player2_Name'],
            'bet_on_p1': bet_on_p1,
            'actual_p1_win': actual_p1_win,
            'model_p1_prob': model_p1_prob,
            'model_prob_bet_on': model_prob_used,
            'market_prob_bet_on': market_prob_used,
            'edge': edge_used,
            'kelly_fraction': kelly_frac,
            'ideal_bet_amount': bet_amount,
            'actual_bet_amount': bet_amount,
            'bankroll_before': ACTUAL_BANKROLL - profit,
            'bet_amount': bet_amount,
            'bet_as_pct_bankroll': kelly_frac,  # Based on fixed $100
            'odds_used': odds_used,
            'bet_won': bet_won,
            'profit': profit,
            'bankroll_after': ACTUAL_BANKROLL,
            'bankroll_growth': ACTUAL_BANKROLL / 100.0,
            'total_return_pct': ((ACTUAL_BANKROLL - 100) / 100) * 100
        })
    
    win_rate = winning_bets / total_bets if total_bets > 0 else 0
    total_return_pct = ((ACTUAL_BANKROLL - 100) / 100) * 100
    
    return {
        'model_name': model_name,
        'final_bankroll': ACTUAL_BANKROLL,
        'total_return_pct': total_return_pct,
        'total_bets': total_bets,
        'winning_bets': winning_bets,
        'win_rate': win_rate,
        'total_profit': total_profit,
        'bet_history': bet_history
    }

# Run fixed bankroll Kelly for all models
fixed_kelly_results = {}
for model_name in model_predictions.keys():
    print(f"\nRunning Fixed Bankroll Kelly for {model_name.replace('_', ' ')}...")
    result = run_fixed_bankroll_kelly(
        model_name,
        model_predictions[model_name],
        model_probabilities[model_name],
        tennis_100_verified,
        ml_verified_df
    )
    fixed_kelly_results[model_name] = result
    print(f"   Final bankroll: ${result['final_bankroll']:.2f}")
    print(f"   Total return: {result['total_return_pct']:+.1f}%")
    print(f"   Bets placed: {result['total_bets']:,}")
    print(f"   Win rate: {result['win_rate']:.1%}")

# Save fixed bankroll Kelly logs
print(f"\n11. Saving fixed bankroll Kelly logs...")
for model_name, result in fixed_kelly_results.items():
    if len(result['bet_history']) > 0:
        bet_df = pd.DataFrame(result['bet_history'])
        filename = f"analysis_scripts/betting_logs/fixed_kelly_{model_name.lower()}_bets.csv"
        bet_df.to_csv(filename, index=False)
        print(f"   {model_name} fixed Kelly log saved: {filename}")

# Create comparison chart: Regular Kelly vs Fixed Bankroll Kelly
print(f"\n12. Creating Kelly comparison charts...")
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('Regular Kelly vs Fixed Bankroll Kelly Comparison', fontsize=16, fontweight='bold')

model_positions = {
    'XGBoost': (0, 0),
    'Random_Forest': (0, 1),
    'Neural_Network_143': (1, 0),
    'Neural_Network_98': (1, 1)
}

for model_name in model_predictions.keys():
    if model_name in model_positions and model_name in kelly_results and model_name in fixed_kelly_results:
        row, col = model_positions[model_name]
        ax = axes[row, col]
        
        # Plot both strategies
        regular_df = pd.DataFrame(kelly_results[model_name]['bet_history'])
        fixed_df = pd.DataFrame(fixed_kelly_results[model_name]['bet_history'])
        
        if len(regular_df) > 0:
            ax.plot(regular_df['bet_number'], regular_df['bankroll_after'], 
                   label='Regular Kelly', linewidth=2, alpha=0.8)
        
        if len(fixed_df) > 0:
            ax.plot(fixed_df['bet_number'], fixed_df['bankroll_after'], 
                   label='Fixed Bankroll Kelly', linewidth=2, alpha=0.8)
        
        display_name = model_name.replace('_', ' ').replace('Neural Network', 'NN')
        regular_return = kelly_results[model_name]['total_return_pct']
        fixed_return = fixed_kelly_results[model_name]['total_return_pct']
        
        ax.set_title(f'{display_name}\\nRegular: {regular_return:+.1f}% | Fixed: {fixed_return:+.1f}%', 
                    fontsize=11, fontweight='bold')
        ax.set_xlabel('Bet Number', fontsize=10)
        ax.set_ylabel('Bankroll ($)', fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # Format y-axis
        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))
        
        # Add horizontal line at $100
        ax.axhline(y=100, color='black', linestyle='--', alpha=0.5, linewidth=1)

plt.tight_layout()
plt.savefig('analysis_scripts/charts/kelly_comparison_regular_vs_fixed.png', 
            dpi=300, bbox_inches='tight', facecolor='white')
print(f"   Kelly comparison chart saved: analysis_scripts/charts/kelly_comparison_regular_vs_fixed.png")
plt.close()

# Results summary comparison
print(f"\n" + "="*80)
print(f"KELLY STRATEGY COMPARISON SUMMARY")
print(f"="*80)
print(f"{'Model':<20} {'Regular Kelly':<15} {'Fixed Bankroll':<15} {'Difference':<12}")
print("-" * 70)

for model_name in model_predictions.keys():
    if model_name in kelly_results and model_name in fixed_kelly_results:
        regular_return = kelly_results[model_name]['total_return_pct']
        fixed_return = fixed_kelly_results[model_name]['total_return_pct']
        difference = regular_return - fixed_return
        
        display_name = model_name.replace('_', ' ')[:19]
        print(f"{display_name:<20} {regular_return:+.1f}%{'':<10} {fixed_return:+.1f}%{'':<10} {difference:+.1f}%{'':<7}")

print(f"\nüí° INSIGHTS:")
print(f"‚úÖ Fixed Bankroll Kelly eliminates compounding luck amplification")
print(f"‚úÖ Still bets proportionally to edge (bigger edge = bigger bet)")
print(f"‚úÖ Provides more stable, comparable results across models")
print(f"‚úÖ Shows true model performance without early luck distortion")

# Additional Kelly Strategies: Full, Half, Quarter Kelly
print(f"\n" + "="*80)
print(f"ADDITIONAL KELLY STRATEGIES COMPARISON")
print(f"(Full Kelly, Half Kelly, Quarter Kelly)")
print(f"="*80)

def run_fractional_kelly(model_name, predictions, probabilities, verified_tennis_data, verified_ml_data, kelly_fraction_multiplier=1.0, max_bet_pct=None):
    """Run Kelly betting with fractional multiplier (0.25=Quarter, 0.5=Half, 1.0=Full)"""
    STARTING_BANKROLL = 100.0
    bankroll = STARTING_BANKROLL
    MIN_EDGE = 0.02
    MIN_BET = 0.01
    
    total_bets = 0
    winning_bets = 0
    total_profit = 0
    bet_history = []

    for i in range(len(verified_ml_data)):
        tennis_row = verified_tennis_data.iloc[i]
        ml_row = verified_ml_data.iloc[i]
        
        # Get betting odds (same logic as before)
        avg_winner_odds = tennis_row.get('AvgW', None)
        avg_loser_odds = tennis_row.get('AvgL', None)
        
        if pd.isna(avg_winner_odds) or pd.isna(avg_loser_odds) or avg_winner_odds <= 1 or avg_loser_odds <= 1:
            continue
            
        avg_winner_odds = float(avg_winner_odds)
        avg_loser_odds = float(avg_loser_odds)
        
        actual_p1_win = ml_row['Player1_Wins']
        if actual_p1_win == 1:
            p1_odds = avg_winner_odds
            p2_odds = avg_loser_odds
        else:
            p1_odds = avg_loser_odds
            p2_odds = avg_winner_odds
        
        model_p1_prob = probabilities[i] if i < len(probabilities) else 0.5
        
        market_p1_prob = 1.0 / p1_odds
        market_p2_prob = 1.0 / p2_odds
        
        edge_p1 = model_p1_prob - market_p1_prob
        edge_p2 = (1 - model_p1_prob) - market_p2_prob
        
        # Determine best bet
        bet_on_p1 = None
        odds_used = None
        model_prob_used = None
        market_prob_used = None
        edge_used = None
        
        if edge_p1 > MIN_EDGE and edge_p1 > edge_p2:
            bet_on_p1 = True
            odds_used = p1_odds
            model_prob_used = model_p1_prob
            market_prob_used = market_p1_prob
            edge_used = edge_p1
        elif edge_p2 > MIN_EDGE:
            bet_on_p1 = False
            odds_used = p2_odds
            model_prob_used = 1 - model_p1_prob
            market_prob_used = market_p2_prob
            edge_used = edge_p2
        else:
            continue
        
        # Calculate Kelly bet size with fractional multiplier
        b = odds_used - 1
        p = model_prob_used
        q = 1 - p
        kelly_frac = (b * p - q) / b
        kelly_frac = max(0, kelly_frac * kelly_fraction_multiplier)
        
        # Apply max bet cap if specified
        if max_bet_pct is not None:
            kelly_frac = min(kelly_frac, max_bet_pct)
            
        bet_amount = bankroll * kelly_frac
        
        if bet_amount < MIN_BET or bankroll < MIN_BET:
            continue
            
        # Calculate outcome
        bet_won = (bet_on_p1 and actual_p1_win == 1) or (not bet_on_p1 and actual_p1_win == 0)
        
        if bet_won:
            profit = bet_amount * (odds_used - 1)
            winning_bets += 1
        else:
            profit = -bet_amount
            
        bankroll += profit
        total_profit += profit
        total_bets += 1
        
        # Log bet
        bet_history.append({
            'bet_number': total_bets,
            'match_index': i,
            'date': ml_row.get('tourney_date', ''),
            'player1': ml_row.get('Player1_Name', ''),
            'player2': ml_row.get('Player2_Name', ''),
            'bet_on_player': ml_row['Player1_Name'] if bet_on_p1 else ml_row['Player2_Name'],
            'bet_on_p1': bet_on_p1,
            'actual_p1_win': actual_p1_win,
            'model_p1_prob': model_p1_prob,
            'model_prob_bet_on': model_prob_used,
            'market_prob_bet_on': market_prob_used,
            'edge': edge_used,
            'kelly_fraction': kelly_frac,
            'bankroll_before': bankroll - profit,
            'bet_amount': bet_amount,
            'bet_as_pct_bankroll': kelly_frac,
            'odds_used': odds_used,
            'bet_won': bet_won,
            'profit': profit,
            'bankroll_after': bankroll,
            'bankroll_growth': bankroll / STARTING_BANKROLL,
            'total_return_pct': ((bankroll - STARTING_BANKROLL) / STARTING_BANKROLL) * 100
        })
    
    win_rate = winning_bets / total_bets if total_bets > 0 else 0
    total_return_pct = ((bankroll - STARTING_BANKROLL) / STARTING_BANKROLL) * 100
    
    return {
        'model_name': model_name,
        'final_bankroll': bankroll,
        'total_return_pct': total_return_pct,
        'total_bets': total_bets,
        'winning_bets': winning_bets,
        'win_rate': win_rate,
        'total_profit': total_profit,
        'bet_history': bet_history
    }

def run_hybrid_fractional_kelly(model_name, predictions, probabilities, verified_tennis_data, verified_ml_data, bankroll_fraction=0.02):
    """Run Full Kelly but only risk a fraction of total bankroll (e.g., 5%)"""
    STARTING_BANKROLL = 100.0
    bankroll = STARTING_BANKROLL
    MIN_EDGE = 0.02
    MIN_BET = 0.01
    
    total_bets = 0
    winning_bets = 0
    total_profit = 0
    bet_history = []

    for i in range(len(verified_ml_data)):
        tennis_row = verified_tennis_data.iloc[i]
        ml_row = verified_ml_data.iloc[i]
        
        # Get betting odds (same logic as before)
        avg_winner_odds = tennis_row.get('AvgW', None)
        avg_loser_odds = tennis_row.get('AvgL', None)
        
        if pd.isna(avg_winner_odds) or pd.isna(avg_loser_odds) or avg_winner_odds <= 1 or avg_loser_odds <= 1:
            continue
            
        avg_winner_odds = float(avg_winner_odds)
        avg_loser_odds = float(avg_loser_odds)
        
        actual_p1_win = ml_row['Player1_Wins']
        if actual_p1_win == 1:
            p1_odds = avg_winner_odds
            p2_odds = avg_loser_odds
        else:
            p1_odds = avg_loser_odds
            p2_odds = avg_winner_odds
        
        # Model probabilities
        p1_prob = probabilities[i] if i < len(probabilities) else 0.5
        p2_prob = 1 - p1_prob
        
        # Calculate market probabilities and edges (same logic as other strategies)
        market_p1_prob = 1.0 / p1_odds
        market_p2_prob = 1.0 / p2_odds
        
        edge_p1 = p1_prob - market_p1_prob
        edge_p2 = p2_prob - market_p2_prob
        
        # Calculate Kelly fractions (for bet sizing only)
        kelly_p1 = kelly_fraction(p1_prob, p1_odds)
        kelly_p2 = kelly_fraction(p2_prob, p2_odds)
        
        bet_placed = False
        bet_amount = 0
        bet_won = False
        bet_on_p1 = None
        odds_used = None
        
        # Use same edge-based betting decision as other strategies
        if edge_p1 > MIN_EDGE and edge_p1 > edge_p2:
            # Bet the Kelly fraction, but only risk the specified fraction of bankroll
            bet_amount = bankroll * kelly_p1 * bankroll_fraction
            bet_amount = max(MIN_BET, bet_amount)  # Ensure minimum bet
            bet_on_p1 = True
            odds_used = p1_odds
            bet_won = (actual_p1_win == 1)
            bet_placed = True
        elif edge_p2 > MIN_EDGE:
            # Bet the Kelly fraction, but only risk the specified fraction of bankroll
            bet_amount = bankroll * kelly_p2 * bankroll_fraction
            bet_amount = max(MIN_BET, bet_amount)  # Ensure minimum bet
            bet_on_p1 = False
            odds_used = p2_odds
            bet_won = (actual_p1_win == 0)
            bet_placed = True
        
        if bet_placed and bet_amount <= bankroll:
            total_bets += 1
            
            if bet_won:
                profit = bet_amount * (odds_used - 1)
                winning_bets += 1
            else:
                profit = -bet_amount
            
            bankroll += profit
            total_profit += profit
            
            bet_history.append({
                'bet_number': total_bets,
                'date': ml_row.get('tourney_date', ''),
                'tournament': ml_row.get('tourney_name', ''),
                'player1': ml_row.get('Player1_Name', ''),
                'player2': ml_row.get('Player2_Name', ''),
                'bet_on_p1': bet_on_p1,
                'bet_amount': bet_amount,
                'odds_used': odds_used,
                'model_prob_bet_on': p1_prob if bet_on_p1 else p2_prob,
                'bet_won': bet_won,
                'profit': profit,
                'bankroll_after': bankroll,
                'edge': (p1_prob if bet_on_p1 else p2_prob) - (1/odds_used),
                'kelly_fraction': kelly_p1 if bet_on_p1 else kelly_p2,
                'bankroll_fraction_used': bankroll_fraction
            })
    
    win_rate = winning_bets / total_bets if total_bets > 0 else 0
    total_return_pct = ((bankroll - STARTING_BANKROLL) / STARTING_BANKROLL) * 100
    
    return {
        'model_name': model_name,
        'final_bankroll': bankroll,
        'total_return_pct': total_return_pct,
        'total_bets': total_bets,
        'winning_bets': winning_bets,
        'win_rate': win_rate,
        'total_profit': total_profit,
        'bet_history': bet_history
    }

# Kelly strategy variants - ALL 100 FRACTIONS from 1% to 100%
kelly_strategies = {}

# Generate all 100 Kelly fractions (1%, 2%, 3%, ..., 100%)
for i in range(1, 101):
    multiplier = i / 100.0  # Convert to decimal (1% = 0.01, 2% = 0.02, etc.)
    
    if i == 100:
        # Special case for Full Kelly
        strategy_name = 'Full_Kelly'
        description = 'Full Kelly (100% of optimal)'
    else:
        strategy_name = f'Kelly_{i}pct'
        description = f'{i}% Kelly ({i}% of optimal)'
    
    kelly_strategies[strategy_name] = {
        'multiplier': multiplier,
        'max_cap': None,
        'description': description
    }

print(f"Generated {len(kelly_strategies)} Kelly strategies from 1% to 100%")

all_strategy_results = {}

for strategy_name, strategy_params in kelly_strategies.items():
    print(f"\n{strategy_params['description']}:")
    print("-" * 50)
    
    strategy_results = {}
    
    for model_name in model_predictions.keys():
        result = run_fractional_kelly(
            model_name,
            model_predictions[model_name],
            model_probabilities[model_name],
            tennis_100_verified,
            ml_verified_df,
            kelly_fraction_multiplier=strategy_params['multiplier'],
            max_bet_pct=strategy_params['max_cap']
        )
        
        strategy_results[model_name] = result
        print(f"   {model_name.replace('_', ' ')}: {result['total_return_pct']:+.1f}% ({result['total_bets']} bets, {result['win_rate']:.1%} WR)")
    
    all_strategy_results[strategy_name] = strategy_results

# All fractional Kelly strategies completed above

# Create organized folder structure
print(f"\n13. Creating organized folder structure and saving all strategy logs...")
import shutil

# Create organized folders
base_folders = ['analysis_scripts/betting_logs', 'analysis_scripts/charts']
for folder in base_folders:
    os.makedirs(folder, exist_ok=True)

# Create folder names for all Kelly strategies we generated
strategies_for_files = list(kelly_strategies.keys()) + ['Fixed_Bankroll']
print(f"Creating folders for {len(strategies_for_files)} strategies...")

# Option 1: Organize by Strategy (what I recommend)
for strategy in strategies_for_files:
    os.makedirs(f'analysis_scripts/betting_logs/{strategy}', exist_ok=True)
    os.makedirs(f'analysis_scripts/charts/{strategy}', exist_ok=True)

# Save all strategy logs in organized folders
for strategy_name, strategy_results in all_strategy_results.items():
    for model_name, result in strategy_results.items():
        if len(result['bet_history']) > 0:
            bet_df = pd.DataFrame(result['bet_history'])
            filename = f"analysis_scripts/betting_logs/{strategy_name}/{model_name.lower()}_bets.csv"
            bet_df.to_csv(filename, index=False)

# Also save Fixed Bankroll logs in organized structure
for model_name, result in fixed_kelly_results.items():
    if len(result['bet_history']) > 0:
        bet_df = pd.DataFrame(result['bet_history'])
        filename = f"analysis_scripts/betting_logs/Fixed_Bankroll/{model_name.lower()}_bets.csv"
        bet_df.to_csv(filename, index=False)

# Move original capped Kelly logs to organized folder
original_files = [
    'analysis_scripts/betting_logs/kelly_xgboost_bets.csv',
    'analysis_scripts/betting_logs/kelly_random_forest_bets.csv', 
    'analysis_scripts/betting_logs/kelly_neural_network_143_bets.csv',
    'analysis_scripts/betting_logs/kelly_neural_network_98_bets.csv'
]

for file_path in original_files:
    if os.path.exists(file_path):
        model_name = file_path.split('kelly_')[1].split('_bets.csv')[0]
        new_path = f"analysis_scripts/betting_logs/Kelly_5pct_Cap/{model_name}_bets.csv"
        shutil.move(file_path, new_path)

print(f"   ‚úÖ All strategy logs organized in subfolders by strategy")

# Create comprehensive comparison chart for all strategies
print(f"\n14. Creating comprehensive strategy comparison charts...")

fig, axes = plt.subplots(2, 2, figsize=(20, 16))
fig.suptitle('Comprehensive Kelly Strategy Comparison', fontsize=18, fontweight='bold')

models_to_plot = ['XGBoost', 'Random_Forest', 'Neural_Network_143', 'Neural_Network_98']
model_positions = {
    'XGBoost': (0, 0),
    'Random_Forest': (0, 1),
    'Neural_Network_143': (1, 0), 
    'Neural_Network_98': (1, 1)
}

# Skip individual strategy charts for 100 strategies - too many to chart individually
print("15. Skipping individual strategy charts (100 strategies is too many for individual visualization)")
print("    Use the comprehensive Kelly analysis to create focused charts")

# strategy_colors and strategy_labels commented out - not needed for 100 strategies
# strategy_colors = {...}  # Would need 100+ colors
# strategy_labels = {...}   # Would need 100+ labels

# Commented out plotting section - too many strategies to chart individually (100 strategies)
# Individual strategy charts would be overwhelming with 100+ strategies
# Use the comprehensive Kelly analysis for focused visualization

# for model_name in models_to_plot: ...
# [Entire plotting section commented out]

print("   ‚úÖ Skipped comprehensive comparison chart (use comprehensive Kelly analysis instead)")

# Create individual charts for each strategy (like the original Kelly charts)
print(f"\n15. Creating individual strategy charts...")

# Define all strategies including the original ones
# COMMENTED OUT - These strategy names don't exist with 100 Kelly fraction generation
# Use comprehensive Kelly analysis for charts instead
# all_strategies_for_charts = {
#     'Kelly_5pct_Cap': {'data': kelly_results, 'description': 'Kelly 5% Cap Strategy'},
#     'Full_Kelly': {'data': all_strategy_results['Full_Kelly'], 'description': 'Full Kelly Strategy'},
#     'Half_Kelly': {'data': all_strategy_results['Half_Kelly'], 'description': 'Half Kelly Strategy'},
#     'Quarter_Kelly': {'data': all_strategy_results['Quarter_Kelly'], 'description': 'Quarter Kelly Strategy'},
#     'Tenth_Kelly': {'data': all_strategy_results['Tenth_Kelly'], 'description': '1/50 Kelly Strategy'},
#     'Hybrid_Fractional_Kelly': {'data': all_strategy_results['Hybrid_Fractional_Kelly'], 'description': 'Hybrid Fractional Kelly Strategy'},
#     'Fixed_Bankroll': {'data': fixed_kelly_results, 'description': 'Fixed Bankroll Kelly Strategy'}
# }

# With 100 Kelly strategies, use comprehensive Kelly analysis for visualization
all_strategies_for_charts = {
    'Kelly_5pct_Cap': {'data': kelly_results, 'description': 'Kelly 5% Cap Strategy'},
    'Full_Kelly': {'data': all_strategy_results['Full_Kelly'], 'description': 'Full Kelly Strategy'},
    'Fixed_Bankroll': {'data': fixed_kelly_results, 'description': 'Fixed Bankroll Kelly Strategy'}
}

colors_for_individual = {
    'XGBoost': '#2E86AB',
    'Random_Forest': '#A23B72', 
    'Neural_Network_143': '#F18F01',
    'Neural_Network_98': '#C73E1D'
}

for strategy_name, strategy_info in all_strategies_for_charts.items():
    strategy_data = strategy_info['data']
    strategy_desc = strategy_info['description']
    
    # Create 2x2 subplot for all 4 models in this strategy
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'{strategy_desc}: Bankroll Over Time', fontsize=16, fontweight='bold')
    
    for model_name in model_predictions.keys():
        if model_name in strategy_data and model_name in model_positions:
            row, col = model_positions[model_name]
            ax = axes[row, col]
            
            result = strategy_data[model_name]
            if len(result['bet_history']) > 0:
                bet_df = pd.DataFrame(result['bet_history'])
                
                # Plot bankroll over bet number
                ax.plot(bet_df['bet_number'], bet_df['bankroll_after'], 
                        color=colors_for_individual[model_name], linewidth=2, alpha=0.8)
                
                # Clean model name for display
                display_name = model_name.replace('_', ' ').replace('Neural Network', 'Neural Net')
                
                # Format final return percentage
                final_return = result['total_return_pct']
                if final_return >= 0:
                    return_text = f"+{final_return:.1f}%"
                    return_color = 'green'
                else:
                    return_text = f"{final_return:.1f}%"
                    return_color = 'red'
                
                ax.set_title(f'{display_name}\\n{return_text} Return ({result["total_bets"]} bets)', 
                            fontsize=12, fontweight='bold', color=return_color)
                ax.set_xlabel('Bet Number', fontsize=10)
                ax.set_ylabel('Bankroll ($)', fontsize=10)
                ax.grid(True, alpha=0.3)
                
                # Format y-axis to avoid scientific notation
                ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))
                
                # Set reasonable y-axis limits
                max_bankroll = bet_df['bankroll_after'].max()
                min_bankroll = bet_df['bankroll_after'].min()
                
                if max_bankroll > 1000:
                    ax.set_ylim(bottom=max(0, min_bankroll * 0.9))
                else:
                    ax.set_ylim(0, max_bankroll * 1.1)
                
                # Add horizontal line at starting bankroll ($100)
                ax.axhline(y=100, color='black', linestyle='--', alpha=0.5, linewidth=1)
                ax.text(0.02, 0.95, 'Start: $100', transform=ax.transAxes, 
                        fontsize=9, verticalalignment='top', alpha=0.7)
            else:
                # Handle case where model has no bets
                ax.text(0.5, 0.5, 'No bets placed', transform=ax.transAxes,
                       ha='center', va='center', fontsize=12, alpha=0.5)
                ax.set_title(f'{model_name.replace("_", " ")}\\nNo bets', 
                           fontsize=12, fontweight='bold')
    
    plt.tight_layout()
    # Save combined chart in strategy-specific folder
    combined_filename = f'analysis_scripts/charts/{strategy_name}/{strategy_name}_bankroll_overtime_all_models.png'
    plt.savefig(combined_filename, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"   {strategy_desc} combined chart saved: {combined_filename}")
    plt.close()
    
    # Also create individual charts for each model in this strategy
    for model_name in model_predictions.keys():
        if model_name in strategy_data:
            result = strategy_data[model_name]
            if len(result['bet_history']) > 0:
                plt.figure(figsize=(12, 8))
                
                bet_df = pd.DataFrame(result['bet_history'])
                
                plt.plot(bet_df['bet_number'], bet_df['bankroll_after'], 
                        color=colors_for_individual[model_name], linewidth=2.5)
                
                display_name = model_name.replace('_', ' ').replace('Neural Network', 'Neural Net')
                final_return = result['total_return_pct']
                
                if final_return >= 0:
                    return_text = f"+{final_return:.1f}%"
                    title_color = 'darkgreen'
                else:
                    return_text = f"{final_return:.1f}%"
                    title_color = 'darkred'
                    
                plt.title(f'{display_name} - {strategy_desc}\\n{return_text} Return ({result["total_bets"]} bets, {result["win_rate"]:.1%} win rate)', 
                         fontsize=14, fontweight='bold', color=title_color, pad=20)
                plt.xlabel('Bet Number', fontsize=12)
                plt.ylabel('Bankroll ($)', fontsize=12)
                plt.grid(True, alpha=0.3)
                
                # Format y-axis nicely
                plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))
                
                # Add horizontal line at starting bankroll
                plt.axhline(y=100, color='black', linestyle='--', alpha=0.5, linewidth=1, label='Starting Bankroll')
                
                # Set y-axis limits
                max_bankroll = bet_df['bankroll_after'].max()
                min_bankroll = bet_df['bankroll_after'].min()
                
                if max_bankroll > 1000:
                    plt.ylim(bottom=max(0, min_bankroll * 0.9))
                else:
                    plt.ylim(0, max_bankroll * 1.1)
                
                plt.tight_layout()
                # Save individual chart in strategy-specific folder
                individual_filename = f"analysis_scripts/charts/{strategy_name}/{model_name.lower()}_bankroll_overtime.png"
                plt.savefig(individual_filename, dpi=300, bbox_inches='tight', facecolor='white')
                print(f"   {display_name} individual chart saved: {individual_filename}")
                plt.close()

print(f"   ‚úÖ Individual charts created for all 5 strategies √ó 4 models = 20 individual charts")
print(f"   ‚úÖ Combined charts created for all 5 strategies = 5 combined charts")

print(f"\n16. Creating log-scale charts for exponential growth cases...")
# Define threshold for exponential growth that needs log-scale visualization
EXPONENTIAL_THRESHOLD = 1000  # 1000%+ return warrants log-scale chart

log_charts_created = 0

for strategy_name, strategy_info in all_strategies_for_charts.items():
    strategy_data = strategy_info['data']
    strategy_desc = strategy_info['description']
    
    # Check which models have exponential growth in this strategy
    exponential_models = []
    for model_name in model_predictions.keys():
        if model_name in strategy_data:
            result = strategy_data[model_name]
            if result['total_return_pct'] > EXPONENTIAL_THRESHOLD and len(result['bet_history']) > 0:
                exponential_models.append(model_name)
    
    if exponential_models:
        print(f"   Creating log-scale charts for {strategy_desc}: {[m.replace('_', ' ') for m in exponential_models]}")
        
        # Create individual log-scale charts for exponential models
        for model_name in exponential_models:
            result = strategy_data[model_name]
            bet_df = pd.DataFrame(result['bet_history'])
            
            plt.figure(figsize=(12, 8))
            
            # Plot with log scale on y-axis
            plt.plot(bet_df['bet_number'], bet_df['bankroll_after'], 
                    color=colors_for_individual[model_name], linewidth=2.5)
            
            # Set log scale
            plt.yscale('log')
            
            display_name = model_name.replace('_', ' ').replace('Neural Network', 'Neural Net')
            final_return = result['total_return_pct']
            
            return_text = f"+{final_return:.1f}%"
            title_color = 'darkgreen'
                
            plt.title(f'{display_name} - {strategy_desc} (Log Scale)\n{return_text} Return ({result["total_bets"]} bets, {result["win_rate"]:.1%} win rate)', 
                     fontsize=14, fontweight='bold', color=title_color, pad=20)
            plt.xlabel('Bet Number', fontsize=12)
            plt.ylabel('Bankroll ($) - Log Scale', fontsize=12)
            plt.grid(True, alpha=0.3)
            
            # Add horizontal line at starting bankroll ($100)
            plt.axhline(y=100, color='black', linestyle='--', alpha=0.7, linewidth=2)
            plt.text(0.02, 0.95, 'Start: $100', transform=plt.gca().transAxes, 
                    fontsize=11, verticalalignment='top', alpha=0.8, fontweight='bold')
            
            # Format y-axis for log scale - show key values
            from matplotlib.ticker import LogFormatter, FixedLocator
            
            # Add some key reference points
            max_bankroll = bet_df['bankroll_after'].max()
            if max_bankroll > 1000:
                plt.axhline(y=1000, color='gray', linestyle=':', alpha=0.5, linewidth=1)
                plt.text(0.02, 0.85, '$1,000', transform=plt.gca().transAxes, 
                        fontsize=9, verticalalignment='top', alpha=0.6)
            if max_bankroll > 10000:
                plt.axhline(y=10000, color='gray', linestyle=':', alpha=0.5, linewidth=1)
                plt.text(0.02, 0.75, '$10,000', transform=plt.gca().transAxes, 
                        fontsize=9, verticalalignment='top', alpha=0.6)
            
            plt.tight_layout()
            
            # Save log-scale chart
            log_filename = f"analysis_scripts/charts/{strategy_name}/{model_name.lower()}_bankroll_overtime_logscale.png"
            plt.savefig(log_filename, dpi=300, bbox_inches='tight', facecolor='white')
            print(f"     Log-scale chart saved: {log_filename}")
            plt.close()
            
            log_charts_created += 1

if log_charts_created > 0:
    print(f"   ‚úÖ {log_charts_created} log-scale charts created for exponential growth cases")
    print(f"   ‚úÖ Total charts generated: {26 + log_charts_created} charts")
else:
    print(f"   No exponential growth cases detected (>{EXPONENTIAL_THRESHOLD}% return)")
    print(f"   ‚úÖ Total charts generated: 26 charts")

# Final strategy comparison table - COMMENTED OUT
# These strategy names don't exist with 100 Kelly fraction generation
# Use comprehensive Kelly analysis for detailed comparisons
print(f"\n" + "="*80)
print(f"BASIC KELLY STRATEGY COMPARISON")
print(f"="*80)
print(f"{'Model':<20} {'Kelly 5%':<12} {'Full Kelly':<12} {'Fixed':<12}")
print("-" * 60)

for model_name in model_predictions.keys():
    display_name = model_name.replace('_', ' ')[:19]
    
    # Get returns for available strategies
    kelly_5_return = kelly_results[model_name]['total_return_pct'] if model_name in kelly_results else 0
    full_return = all_strategy_results['Full_Kelly'][model_name]['total_return_pct'] if model_name in all_strategy_results['Full_Kelly'] else 0
    fixed_return = fixed_kelly_results[model_name]['total_return_pct'] if model_name in fixed_kelly_results else 0
    
    print(f"{display_name:<20} {kelly_5_return:+.1f}%{'':<6} {full_return:+.1f}%{'':<6} {fixed_return:+.1f}%{'':<6}")

print(f"\nüéØ KELLY STRATEGY INSIGHTS:")
print(f"‚úÖ Full Kelly: Maximum growth but extreme volatility (can lose everything)")
print(f"‚úÖ Kelly 5% Cap: Conservative approach with limited downside")
print(f"‚úÖ Fixed Bankroll: Eliminates compounding luck, shows true skill")
print(f"‚úÖ ALL 100 Kelly fractions generated - use comprehensive analysis for detailed comparison")

# Final Kelly results summary
print(f"\n" + "="*80)
print(f"KELLY BETTING RESULTS SUMMARY")
print(f"="*80)

kelly_sorted = sorted(kelly_results.items(), key=lambda x: x[1]['total_return_pct'], reverse=True)

print(f"Profitability Rankings:")
for i, (model_name, result) in enumerate(kelly_sorted):
    display_name = model_name.replace('_', ' ')
    print(f"   {i+1}. {display_name}: {result['total_return_pct']:+.1f}% ({result['total_bets']} bets, {result['win_rate']:.1%} win rate)")

# Check if any models are profitable
profitable_models = [name for name, result in kelly_results.items() if result['total_return_pct'] > 0]
if profitable_models:
    print(f"\nüéâ PROFITABLE MODELS:")
    for model in profitable_models:
        result = kelly_results[model]
        print(f"   {model.replace('_', ' ')}: {result['total_return_pct']:+.1f}% return")
else:
    print(f"\nüìä No models showed profitability with Kelly betting")

print(f"\n‚úÖ Complete analysis with betting simulation finished!")
print(f"‚úÖ {len([r for r in kelly_results.values() if len(r['bet_history']) > 0])} models generated betting logs")
print(f"‚úÖ {len([r for r in kelly_results.values() if len(r['bet_history']) > 0])} bankroll charts generated")
print(f"‚úÖ All results tested on {len(ml_verified_df):,} 100% verified identical matches")